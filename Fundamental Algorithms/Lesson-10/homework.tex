\documentclass[11pt]{article}
\pagestyle{empty}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[options]{algorithm2e}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\cfoot[R]{\thepage~of~\pageref{LastPage}}
\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}
\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\begin{document}
\begin{center} {\Large\bf FA, Homework 10} \\ Quentin McGaw (qm301) \\ 04/20/17
\end{center}

\begin{quote}
The world is teeming; anything can happen
\\ John Cage, Silence
\end{quote}

\begin{itemize}
    \item \textbf{Kruskal's algorithm:}
    \begin{enumerate}
        \item Sort all the edges in increasing order of their weight in the array $A$
        \item Pick the smallest edge from $A$. If it does not form a cycle with the spanning tree formed $S$ so far, include it in $S$. Then remove it from $A$.
        \item Repeat step 2 until there are $V-1$ edges in $S$, where $V$ is the number of vertices in the graph.
    \end{enumerate}
    \item \textbf{Kruskal's algorithm pseudo-code:}
    \begin{enumerate}
        \item We sort the edges $e_1, ..., e_E$ by weight
        \item $x_i$ and $y_i$ are the vertices of $e_i$.
    \end{enumerate}
    \begin{algorithm}[H]
        \For{each vertex $x$}{
            $\pi[x] = x$ \\
            $SIZE(x) = 1$ \\
        }
        $S = \{\}$ \\
        \For{i from 1 to E}{
            \While{$\pi[x_i] \neq x_i$}{
                $x_i = \pi[x_i]$ (finds its highest parent)
            }
            \While{$\pi[y_i] \neq y_i$}{
                $y_i = \pi[y_i]$ (finds its highest parent)
            }
            \If{$x_i \neq y_i$}{
                \If{$SIZE(x_i) \leq SIZE(y_i)$}{
                    $\pi[x_i] = y_i$ \\
                    $SIZE(y_i) = SIZE(y_i) + SIZE(x_i)$
                }
                \Else{
                    $\pi[y_i] = x_i$ \\
                    $SIZE(x_i) = SIZE(x_i) + SIZE(y_i)$
                }
                $S$.add($e_i$)
            }
        }
        \Return{$S$}
    \end{algorithm}
\end{itemize}

\begin{enumerate}
\item \textbf{\textcolor{blue}{Suppose we are given the Minimal Spanning Tree $T$ of a graph $G$.  Now we take an edge $\{x,y\}$ of $G$ which is not in $T$ and reduce its weight $w(x,y)$ to a new value $w$.  Suppose the path from $x$ to $y$ in the Minimal Spanning Tree contains an edge whose weight is bigger than $w$.  Prove that the old Minimal Spanning Tree is no longer the Minimal Spanning Tree.}}
    \\ It is stated that the path from $x$ to $y$ contains an edge whose weight is bigger than $w$ so the weight of of the path from $x$ to $y$ must be greater than $w$. On the other hand, we reduce the weight $w$ of the edge $\{x,y\}$ therefore the path from $x$ to $y$ with the lowest weight has now changed with this new graph and has a weight of $w$. The MST based on the initial graph is therefore invalid with this modified graph as there is now a path from $x$ to $y$ with a lower weight.
    
\item \textbf{\textcolor{blue}{Suppose we ran Kruskal's algorithm on a graph $G$ with $n$ vertices and $m$ edges, no two costs equal. {\em Assume} that the $n-1$ edges of minimal cost form a tree $T$.}}
\begin{enumerate}
    \item \textbf{\textcolor{blue}{Argue that $T$ will be the minimal cost tree.}}
        \\ First we know that every edge cost is unique from the problem. From the minimum-cost edge property of the MST, we know that if the minimum cost edge e of a graph is unique, then this edge is included in any MST. Therefore, $T$ is a minimal cost tree.
        \\ From the uniqueness property of the MST and because each edge cost is unique, there is only one MST which must be $T$.
        \\ Therefore $T$ is the minimal cost tree.
    \item \textbf{\textcolor{blue}{How much time will Kruskal's Algorithm take. {\em Assume} that the edges are {\em given} to you as an array in increasing order of weight. Further, {\em assume} the Algorithm stops when it finds the MST. Note that the total number $m$ of edges is irrelevant as the algorithm will only look at the first $n-1$ of them.}}
        \\ Because the edges are already sorted in increasing order of weight, we only need to add edges to the MST from the edge with the smallest weight until the edge of the largest weight (or $n-1$ edges) that don't form a cycle. To do this we use disjoint-set data structures which require $n$ UNION[x,y] each taking $O(\ln(n))$ hence we need a total time of $O(n\ln(n))$.
    \item \textbf{\textcolor{blue}{We define Dumb Kruskal. It is Kruskal without the SIZE function. For $UNION[u,v]$ we follow $u,v$ down to their roots $x,y$ as with regular Kruskal but now, if $x\neq y$, we simply reset $\pi[y]=x$. We have the same assumptions on $G$ as above. How long could dumb Kruskal take. Describe an example where it takes that long. (You can imagine that when the edge $u,v$ is given an adversary puts them in the worst possible order to slow down your algorithm.)}}
        \\ As there are $n$ vertices, UNION[x,y] takes $O(n)$ time so the algorithm takes $O(n^2)$ time.
        \\ To make this happen, we can suppose the edges are given in the following order: $\{2,1\}$, $\{3,1\}$, ..., $\{n,1\}$.
        We set $\pi[1] = 2$ for the first edge. We follow 1 down to 2 and we set $\pi[2] = 3$. For the $i^{th}$ step we need $i$ time so this would effectively take $\Theta(n^2)$ time overall.
\end{enumerate}

\item \textbf{\textcolor{blue}{Consider Kruskal's Algorithm for MST on a graph with vertex set $\{1,\ldots,n\}$. Assume that the order of the weights of the edges begins $\{1,2\}, \{2,3\}, \{3,4\},\ldots, \{n-1,n\}$. (Note: When $SIZE[x]=SIZE[y]$ make the first value the parent of the second. In particular, set $\pi[2]=1$, not the other way around.)}}
    \begin{enumerate}
    \item \textbf{\textcolor{blue}{Show the pattern as the edges are processed. In particular, let $n=100$ and stop the program when the edge $\{72,73\}$ has been processed. Give the values of $SIZE[x]$ and $\pi[x]$ for all vertices $x$.}}
        \begin{itemize}
            \item We start with $x_i = 1$ and $y_i = 2$. Because $SIZE(x_i) = SIZE(y_i)$, $\pi[y_i] = x_i= \pi[2] = 1$ and $SIZE[x_i] = SIZE[x_i] + SIZE[y_i] = 1 + 1 = SIZE[1] = 2$. 
            \item For $i = 3,4,...$ when we process $1,i$ we have $\pi[i] = i$ and $\pi[i - 1] = 1$.
            \item The WHILE loop thus sends $i-1$ to ! with $SIZE[1] = i-1$ and $i$ to itself with $SIZE[i] = 1$.
            \item So we set $\pi[i] = 1$ and reset $SIZE[1] = i-1+1 = i$.
            ($SIZE[1]$ is incremented at each iteration).
            \item With $n=100$ after {1,73} is processed we have $\pi[i] = 1$ for $2 \leq i \leq 73$.
            \item For the (untouched) $i$ from 74 to 100 we still have $SIZE[i] = 1$ and $\pi[i] = i$.
        \end{itemize}
    \item \textbf{\textcolor{blue}{Now let $n$ be large and stop the program after $\{n-1,n\}$ has been processed. Assume the ordering of the weights of the edges was {\em given} to you, so it took zero time. How long, as an asymptotic function of $n$, would this program take. (Reasons, please!)}}
        \\ At each iteration, the WHILE loop is not applied for 1 and applied one time for $i$ so it takes constant time. This program has to run for $n - 1$ edges so it takes $\Theta(n)$ time.
    \end{enumerate}

\item \textbf{\textcolor{blue}{Suppose that during Kruskal's Algorithm (for MST) at some point we have $SIZE[v]=37$.}}
\begin{enumerate}
    \item \textbf{\textcolor{blue}{What is the interpretation of that in the case when $\pi[v]=v$?}}
        \\ SIZE[v] = 37 means that the vertex $v$ is in a component of size 37.
        \\ $\pi[v]$ = v means that it is the highest parent of this component so v is the root of the associated tree. 
    \item \textbf{\textcolor{blue}{What is the interpretation of that in the case when $\pi[v]=u\neq v$?}}
        \\ v had a size of 37 when $\pi[v]$ was changed. The component with v was joined to the larger component with another vertex u.
    \item \textbf{\textcolor{blue}{Let $w$ be a vertex. How many different values can $\pi[w]$ have during the course of Kruskal's algorithm?}}
        \\ For a vertex w, $\pi[w]$ can have \textbf{two} values: w (at start) or v (only once).
        \\ Note that a vertex never changes but becomes the root of the final rooted tree.
    \item \textbf{\textcolor{blue}{How many different values (as a function of $V$, the number of vertices) can $SIZE[w]$ have during the course of Kruskal's algorithm? (That is, the maximal number possible.)}}
        \\ If w is joined to isolated vertices $V-1$ times, SIZE[w] goes from 1 to V by ones. Therefore $SIZE[w]$ can have at most $V$ different values.
\end{enumerate}
\end{enumerate}

\begin{quote}
Humans are allergic to change.  They love to say, "We've always done it this way."
I try to fight that.
\\ Grace Hopper
\end{quote}

\end{document}